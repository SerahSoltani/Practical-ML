{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Named_Entity_Recognition_CoNLLpp.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIsYTir1LdWd"
      },
      "source": [
        "# Named Entity Recognition on the CoNLL++ Dataset\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "[Article](https://news.machinelearning.sg/posts/train_a_named_entity_recognition_model_using_flair) | [Github](https://github.com/eugenesiow/practical-ml/blob/master/notebooks/Named_Entity_Recognition_CoNLLpp.ipynb) | More Notebooks @ [eugenesiow/practical-ml](https://github.com/eugenesiow/practical-ml)\r\n",
        "\r\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wEHlNdHL8Nv"
      },
      "source": [
        "Notebook to train a [flair](https://github.com/flairNLP/flair) model using stacked embeddings (with word and flair contextual embeddings) to perform named entity recognition (NER). The dataset used is the [CoNLL 2003](https://www.aclweb.org/anthology/W03-0419.pdf) dataset for NER (train, dev) with a manually corrected (improved/cleaned) test set from the [CrossWeigh paper](https://arxiv.org/abs/1909.01441) called [CoNLL++](https://github.com/ZihanWangKi/CrossWeigh#data). The current state-of-the-art model on this dataset is from the CrossWeigh paper (also using flair) by [Wang et al. (2019)](https://www.aclweb.org/anthology/D19-1519/) with F1-score of [94.3%](http://nlpprogress.com/english/named_entity_recognition.html). Without using pooled-embeddings, CrossWeigh and training to a max 50 instead of 150 epochs, we get a micro F1-score of 93.5%, within 0.7 of a percentage point of the SOTA.\r\n",
        "\r\n",
        "The notebook is structured as follows:\r\n",
        "* Setting up the GPU Environment\r\n",
        "* Getting Data\r\n",
        "* Training and Testing the Model\r\n",
        "* Using the Model (Running Inference)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YbAAbVsOLyp"
      },
      "source": [
        "## Task Description\r\n",
        "\r\n",
        "> Named entity recognition (NER) is the task of tagging entities in text with their corresponding type. Approaches typically use BIO notation, which differentiates the beginning (B) and the inside (I) of entities. O is used for non-entity tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibsCfqKxPwZl"
      },
      "source": [
        "# Setting up the GPU Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EniXBtDPyEZ"
      },
      "source": [
        "#### Ensure we have a GPU runtime\r\n",
        "\r\n",
        "If you're running this notebook in Google Colab, select `Runtime` > `Change Runtime Type` from the menubar. Ensure that `GPU` is selected as the `Hardware accelerator`. This will allow us to use the GPU to train the model subsequently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYu2HDP_P0e5"
      },
      "source": [
        "#### Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5pgQDNVB20K",
        "outputId": "cfb0b75c-4f87-4a8a-d1ce-8219c9d0af50"
      },
      "source": [
        "pip install -q flair"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 450kB 8.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 19.7MB 1.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 58.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3MB 56.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 798kB 57.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 13.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 983kB 49.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 52.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9MB 55.0MB/s \n",
            "\u001b[?25h  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI558IY2P94A"
      },
      "source": [
        "# Getting Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOMnhOfYP_lw"
      },
      "source": [
        "We download the data (train, test and dev sets) in the BIO format (each token in each of the sentences are tagged with Begin, Inside or Outside labels) as text files from the [CoNLL++ repository](https://github.com/ZihanWangKi/CrossWeigh) and save them to the `/content/data/` folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7zEa-M6GBcv"
      },
      "source": [
        "import urllib.request\r\n",
        "from pathlib import Path\r\n",
        "\r\n",
        "def download_file(url, output_file):\r\n",
        "  Path(output_file).parent.mkdir(parents=True, exist_ok=True)\r\n",
        "  urllib.request.urlretrieve (url, output_file)\r\n",
        "\r\n",
        "download_file('https://raw.githubusercontent.com/ZihanWangKi/CrossWeigh/master/data/conllpp_train.txt', '/content/data/conllpp_train.txt')\r\n",
        "download_file('https://raw.githubusercontent.com/ZihanWangKi/CrossWeigh/master/data/conllpp_dev.txt', '/content/data/conllpp_dev.txt')\r\n",
        "download_file('https://raw.githubusercontent.com/ZihanWangKi/CrossWeigh/master/data/conllpp_test.txt', '/content/data/conllpp_test.txt')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0eY1HbQRAOd"
      },
      "source": [
        "Now we will use flair's built in `ColumnCorpus` object to load in our `conllpp_train.txt`, `conllpp_test.txt` and `conllpp_dev.txt` files in the `/content/data/` folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iyyzMULE4JB",
        "outputId": "cd407ab4-41f4-43ef-ae2a-b49498ce8f2b"
      },
      "source": [
        "from flair.data import Corpus\r\n",
        "from flair.datasets import ColumnCorpus\r\n",
        "columns = {0: 'text', 3: 'ner'}\r\n",
        "corpus: Corpus = ColumnCorpus('/content/data/', columns,\r\n",
        "                              train_file='conllpp_train.txt',\r\n",
        "                              test_file='conllpp_test.txt',\r\n",
        "                              dev_file='conllpp_dev.txt')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-22 08:56:56,625 Reading data from /content/data\n",
            "2020-12-22 08:56:56,627 Train: /content/data/conllpp_train.txt\n",
            "2020-12-22 08:56:56,629 Dev: /content/data/conllpp_dev.txt\n",
            "2020-12-22 08:56:56,631 Test: /content/data/conllpp_test.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AY12224EPHqu"
      },
      "source": [
        "To check that the sentences/size of the train, test and development set tally exactly with the Table 1 (train: 14987, test: 3684, dev: 3466) in the [CoNLL 2003 paper](https://www.aclweb.org/anthology/W03-0419.pdf), we will get the `len()` of the `.train`, `.test` and `.dev` sets from the `ColumnCorpus` object and print it out as a table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "2cHUGsJOIoLS",
        "outputId": "de981246-5b09-44eb-f3a9-d9864650b5af"
      },
      "source": [
        "import pandas as pd\r\n",
        "data = [[len(corpus.train), len(corpus.test), len(corpus.dev)]]\r\n",
        "# Prints out the dataset sizes of train test and development in a table.\r\n",
        "pd.DataFrame(data, columns=[\"Train\", \"Test\", \"Development\"])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train</th>\n",
              "      <th>Test</th>\n",
              "      <th>Development</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14987</td>\n",
              "      <td>3684</td>\n",
              "      <td>3466</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Train  Test  Development\n",
              "0  14987  3684         3466"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ltHe5_vR1mw"
      },
      "source": [
        "# Training and Testing the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4H4kP93rR8vA"
      },
      "source": [
        "#### Train the Model\r\n",
        "\r\n",
        "To train the flair `SequenceTagger`, we use the `ModelTrainer` object with the corpus and the tagger to be trained. We use flair's sensible default options while specifying the output folder for the `SequenceTagger` model to be `/content/model/conllpp`. We also set the `embeddings_storage_mode` to be `gpu` to utilise the GPU. Note that if you run this with a larger dataset than CoNLL++ and you run out of GPU memory, be sure to set this option to `cpu`.\r\n",
        "\r\n",
        "Be prepared to allow the training to run for a few hours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV55XbDCI2Dx",
        "outputId": "7452aa44-0525-4a25-8cbd-6d670790f0ae"
      },
      "source": [
        "import flair\r\n",
        "from typing import List\r\n",
        "from flair.trainers import ModelTrainer\r\n",
        "from flair.models import SequenceTagger\r\n",
        "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, FlairEmbeddings\r\n",
        "\r\n",
        "tag_type = 'ner'\r\n",
        "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\r\n",
        "\r\n",
        "# For faster training and smaller models, we can comment out the flair embeddings.\r\n",
        "# This will significantly affect the performance though.\r\n",
        "embedding_types: List[TokenEmbeddings] = [\r\n",
        "    WordEmbeddings('glove'),\r\n",
        "    FlairEmbeddings('news-forward'),\r\n",
        "    FlairEmbeddings('news-backward'),\r\n",
        "]\r\n",
        "\r\n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\r\n",
        "\r\n",
        "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\r\n",
        "                                        embeddings=embeddings,\r\n",
        "                                        tag_dictionary=tag_dictionary,\r\n",
        "                                        tag_type=tag_type,\r\n",
        "                                        use_crf=True)\r\n",
        "\r\n",
        "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\r\n",
        "\r\n",
        "trainer.train('/content/model/conllpp',\r\n",
        "              learning_rate=0.1,\r\n",
        "              mini_batch_size=32,\r\n",
        "              max_epochs=50,\r\n",
        "              embeddings_storage_mode='gpu')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-22 09:46:18,939 epoch 39 - iter 322/469 - loss 0.20560896 - samples/sec: 262.66 - lr: 0.025000\n",
            "2020-12-22 09:46:24,727 epoch 39 - iter 368/469 - loss 0.20580710 - samples/sec: 254.50 - lr: 0.025000\n",
            "2020-12-22 09:46:30,152 epoch 39 - iter 414/469 - loss 0.20611729 - samples/sec: 271.58 - lr: 0.025000\n",
            "2020-12-22 09:46:35,687 epoch 39 - iter 460/469 - loss 0.20844374 - samples/sec: 266.10 - lr: 0.025000\n",
            "2020-12-22 09:46:36,807 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-22 09:46:36,809 EPOCH 39 done: loss 0.2097 - lr 0.0250000\n",
            "2020-12-22 09:46:41,879 DEV : loss 0.3880603313446045 - score 0.9572\n",
            "2020-12-22 09:46:41,898 BAD EPOCHS (no improvement): 1\n",
            "2020-12-22 09:46:41,899 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-22 09:46:47,401 epoch 40 - iter 46/469 - loss 0.18646228 - samples/sec: 267.78 - lr: 0.025000\n",
            "2020-12-22 09:46:52,816 epoch 40 - iter 92/469 - loss 0.19056938 - samples/sec: 272.09 - lr: 0.025000\n",
            "2020-12-22 09:46:58,609 epoch 40 - iter 138/469 - loss 0.20020539 - samples/sec: 254.29 - lr: 0.025000\n",
            "2020-12-22 09:47:04,102 epoch 40 - iter 184/469 - loss 0.20557453 - samples/sec: 268.21 - lr: 0.025000\n",
            "2020-12-22 09:47:09,790 epoch 40 - iter 230/469 - loss 0.21009743 - samples/sec: 258.92 - lr: 0.025000\n",
            "2020-12-22 09:47:15,218 epoch 40 - iter 276/469 - loss 0.20737854 - samples/sec: 271.39 - lr: 0.025000\n",
            "2020-12-22 09:47:20,970 epoch 40 - iter 322/469 - loss 0.20704331 - samples/sec: 256.10 - lr: 0.025000\n",
            "2020-12-22 09:47:26,313 epoch 40 - iter 368/469 - loss 0.20971140 - samples/sec: 275.71 - lr: 0.025000\n",
            "2020-12-22 09:47:31,834 epoch 40 - iter 414/469 - loss 0.20606897 - samples/sec: 266.83 - lr: 0.025000\n",
            "2020-12-22 09:47:37,264 epoch 40 - iter 460/469 - loss 0.20368737 - samples/sec: 271.23 - lr: 0.025000\n",
            "2020-12-22 09:47:38,437 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-22 09:47:38,438 EPOCH 40 done: loss 0.2057 - lr 0.0250000\n",
            "2020-12-22 09:47:43,511 DEV : loss 0.40031811594963074 - score 0.9559\n",
            "2020-12-22 09:47:43,531 BAD EPOCHS (no improvement): 2\n",
            "2020-12-22 09:47:43,532 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-22 09:47:49,009 epoch 41 - iter 46/469 - loss 0.21882616 - samples/sec: 268.95 - lr: 0.025000\n",
            "2020-12-22 09:47:54,644 epoch 41 - iter 92/469 - loss 0.21652355 - samples/sec: 261.40 - lr: 0.025000\n",
            "2020-12-22 09:48:00,465 epoch 41 - iter 138/469 - loss 0.21577834 - samples/sec: 253.00 - lr: 0.025000\n",
            "2020-12-22 09:48:06,027 epoch 41 - iter 184/469 - loss 0.21045093 - samples/sec: 264.87 - lr: 0.025000\n",
            "2020-12-22 09:48:11,426 epoch 41 - iter 230/469 - loss 0.20885527 - samples/sec: 272.83 - lr: 0.025000\n",
            "2020-12-22 09:48:17,102 epoch 41 - iter 276/469 - loss 0.20283952 - samples/sec: 259.46 - lr: 0.025000\n",
            "2020-12-22 09:48:22,712 epoch 41 - iter 322/469 - loss 0.20117582 - samples/sec: 262.60 - lr: 0.025000\n",
            "2020-12-22 09:48:28,147 epoch 41 - iter 368/469 - loss 0.20070918 - samples/sec: 271.03 - lr: 0.025000\n",
            "2020-12-22 09:48:33,525 epoch 41 - iter 414/469 - loss 0.20340127 - samples/sec: 273.93 - lr: 0.025000\n",
            "2020-12-22 09:48:39,442 epoch 41 - iter 460/469 - loss 0.20524988 - samples/sec: 248.94 - lr: 0.025000\n",
            "2020-12-22 09:48:40,543 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-22 09:48:40,544 EPOCH 41 done: loss 0.2040 - lr 0.0250000\n",
            "2020-12-22 09:48:45,617 DEV : loss 0.3976965546607971 - score 0.9566\n",
            "2020-12-22 09:48:45,636 BAD EPOCHS (no improvement): 3\n",
            "2020-12-22 09:48:45,637 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-22 09:48:51,169 epoch 42 - iter 46/469 - loss 0.20381295 - samples/sec: 266.30 - lr: 0.025000\n",
            "2020-12-22 09:48:56,996 epoch 42 - iter 92/469 - loss 0.20045951 - samples/sec: 252.81 - lr: 0.025000\n",
            "2020-12-22 09:49:02,643 epoch 42 - iter 138/469 - loss 0.20964037 - samples/sec: 260.80 - lr: 0.025000\n",
            "2020-12-22 09:49:08,017 epoch 42 - iter 184/469 - loss 0.20337077 - samples/sec: 274.13 - lr: 0.025000\n",
            "2020-12-22 09:49:13,605 epoch 42 - iter 230/469 - loss 0.19682062 - samples/sec: 263.59 - lr: 0.025000\n",
            "2020-12-22 09:49:19,066 epoch 42 - iter 276/469 - loss 0.19780483 - samples/sec: 269.74 - lr: 0.025000\n",
            "2020-12-22 09:49:24,865 epoch 42 - iter 322/469 - loss 0.19146565 - samples/sec: 253.98 - lr: 0.025000\n",
            "2020-12-22 09:49:30,368 epoch 42 - iter 368/469 - loss 0.19961747 - samples/sec: 267.69 - lr: 0.025000\n",
            "2020-12-22 09:49:35,873 epoch 42 - iter 414/469 - loss 0.19880925 - samples/sec: 267.61 - lr: 0.025000\n",
            "2020-12-22 09:49:41,320 epoch 42 - iter 460/469 - loss 0.20256511 - samples/sec: 270.49 - lr: 0.025000\n",
            "2020-12-22 09:49:42,365 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-22 09:49:42,367 EPOCH 42 done: loss 0.2046 - lr 0.0250000\n",
            "2020-12-22 09:49:48,794 DEV : loss 0.3934156596660614 - score 0.9557\n",
            "Epoch    42: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2020-12-22 09:49:48,813 BAD EPOCHS (no improvement): 4\n",
            "2020-12-22 09:49:48,813 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-22 09:49:54,335 epoch 43 - iter 46/469 - loss 0.21418956 - samples/sec: 266.81 - lr: 0.012500\n",
            "2020-12-22 09:49:59,778 epoch 43 - iter 92/469 - loss 0.21570551 - samples/sec: 270.64 - lr: 0.012500\n",
            "2020-12-22 09:50:05,361 epoch 43 - iter 138/469 - loss 0.21180922 - samples/sec: 263.86 - lr: 0.012500\n",
            "2020-12-22 09:50:11,314 epoch 43 - iter 184/469 - loss 0.20827719 - samples/sec: 247.37 - lr: 0.012500\n",
            "2020-12-22 09:50:17,063 epoch 43 - iter 230/469 - loss 0.20334076 - samples/sec: 256.20 - lr: 0.012500\n",
            "2020-12-22 09:50:22,594 epoch 43 - iter 276/469 - loss 0.20137026 - samples/sec: 266.39 - lr: 0.012500\n",
            "2020-12-22 09:50:28,340 epoch 43 - iter 322/469 - loss 0.20159657 - samples/sec: 256.31 - lr: 0.012500\n",
            "2020-12-22 09:50:34,056 epoch 43 - iter 368/469 - loss 0.20060400 - samples/sec: 257.80 - lr: 0.012500\n",
            "2020-12-22 09:50:39,663 epoch 43 - iter 414/469 - loss 0.20053485 - samples/sec: 262.68 - lr: 0.012500\n",
            "2020-12-22 09:50:45,172 epoch 43 - iter 460/469 - loss 0.20155695 - samples/sec: 267.40 - lr: 0.012500\n",
            "2020-12-22 09:50:46,272 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-22 09:50:46,273 EPOCH 43 done: loss 0.2011 - lr 0.0125000\n",
            "2020-12-22 09:50:51,356 DEV : loss 0.3969409465789795 - score 0.9553\n",
            "2020-12-22 09:50:51,378 BAD EPOCHS (no improvement): 1\n",
            "2020-12-22 09:50:51,380 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-22 09:50:56,925 epoch 44 - iter 46/469 - loss 0.19761315 - samples/sec: 265.70 - lr: 0.012500\n",
            "2020-12-22 09:51:02,644 epoch 44 - iter 92/469 - loss 0.19164859 - samples/sec: 257.56 - lr: 0.012500\n",
            "2020-12-22 09:51:08,294 epoch 44 - iter 138/469 - loss 0.19130626 - samples/sec: 260.83 - lr: 0.012500\n",
            "2020-12-22 09:51:14,248 epoch 44 - iter 184/469 - loss 0.18604584 - samples/sec: 247.47 - lr: 0.012500\n",
            "2020-12-22 09:51:19,977 epoch 44 - iter 230/469 - loss 0.18954846 - samples/sec: 257.05 - lr: 0.012500\n",
            "2020-12-22 09:51:25,564 epoch 44 - iter 276/469 - loss 0.19335425 - samples/sec: 263.70 - lr: 0.012500\n",
            "2020-12-22 09:51:31,407 epoch 44 - iter 322/469 - loss 0.19563699 - samples/sec: 252.05 - lr: 0.012500\n",
            "2020-12-22 09:51:37,519 epoch 44 - iter 368/469 - loss 0.19852093 - samples/sec: 240.98 - lr: 0.012500\n",
            "2020-12-22 09:51:43,095 epoch 44 - iter 414/469 - loss 0.19712523 - samples/sec: 264.22 - lr: 0.012500\n",
            "2020-12-22 09:51:48,638 epoch 44 - iter 460/469 - loss 0.19615111 - samples/sec: 265.74 - lr: 0.012500\n",
            "2020-12-22 09:51:49,650 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-22 09:51:49,653 EPOCH 44 done: loss 0.1954 - lr 0.0125000\n",
            "2020-12-22 09:51:54,638 DEV : loss 0.3988956809043884 - score 0.9554\n",
            "2020-12-22 09:51:54,658 BAD EPOCHS (no improvement): 2\n",
            "2020-12-22 09:51:54,659 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-22 09:52:00,335 epoch 45 - iter 46/469 - loss 0.18674531 - samples/sec: 259.57 - lr: 0.012500\n",
            "2020-12-22 09:52:06,054 epoch 45 - iter 92/469 - loss 0.18526623 - samples/sec: 257.61 - lr: 0.012500\n",
            "2020-12-22 09:52:11,638 epoch 45 - iter 138/469 - loss 0.18796100 - samples/sec: 263.89 - lr: 0.012500\n",
            "2020-12-22 09:52:17,215 epoch 45 - iter 184/469 - loss 0.18507618 - samples/sec: 264.16 - lr: 0.012500\n",
            "2020-12-22 09:52:22,644 epoch 45 - iter 230/469 - loss 0.18141420 - samples/sec: 271.40 - lr: 0.012500\n",
            "2020-12-22 09:52:28,166 epoch 45 - iter 276/469 - loss 0.18392966 - samples/sec: 266.80 - lr: 0.012500\n",
            "2020-12-22 09:52:33,603 epoch 45 - iter 322/469 - loss 0.18486689 - samples/sec: 271.01 - lr: 0.012500\n",
            "2020-12-22 09:52:38,995 epoch 45 - iter 368/469 - loss 0.18508799 - samples/sec: 273.17 - lr: 0.012500\n",
            "2020-12-22 09:52:44,624 epoch 45 - iter 414/469 - loss 0.18391162 - samples/sec: 261.73 - lr: 0.012500\n",
            "2020-12-22 09:52:50,128 epoch 45 - iter 460/469 - loss 0.18901565 - samples/sec: 267.60 - lr: 0.012500\n",
            "2020-12-22 09:52:51,260 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-22 09:52:51,261 EPOCH 45 done: loss 0.1894 - lr 0.0125000\n",
            "2020-12-22 09:52:56,411 DEV : loss 0.39434903860092163 - score 0.9556\n",
            "2020-12-22 09:52:56,427 BAD EPOCHS (no improvement): 3\n",
            "2020-12-22 09:52:56,428 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-22 09:53:02,294 epoch 46 - iter 46/469 - loss 0.20456706 - samples/sec: 251.24 - lr: 0.012500\n",
            "2020-12-22 09:53:07,946 epoch 46 - iter 92/469 - loss 0.20287008 - samples/sec: 260.62 - lr: 0.012500\n",
            "2020-12-22 09:53:13,362 epoch 46 - iter 138/469 - loss 0.19931860 - samples/sec: 271.93 - lr: 0.012500\n",
            "2020-12-22 09:53:18,895 epoch 46 - iter 184/469 - loss 0.19217832 - samples/sec: 266.24 - lr: 0.012500\n",
            "2020-12-22 09:53:24,490 epoch 46 - iter 230/469 - loss 0.19147526 - samples/sec: 263.23 - lr: 0.012500\n",
            "2020-12-22 09:53:29,825 epoch 46 - iter 276/469 - loss 0.19232013 - samples/sec: 276.06 - lr: 0.012500\n",
            "2020-12-22 09:53:35,313 epoch 46 - iter 322/469 - loss 0.19304984 - samples/sec: 268.45 - lr: 0.012500\n",
            "2020-12-22 09:53:40,742 epoch 46 - iter 368/469 - loss 0.19137985 - samples/sec: 271.30 - lr: 0.012500\n",
            "2020-12-22 09:53:46,614 epoch 46 - iter 414/469 - loss 0.19307377 - samples/sec: 250.86 - lr: 0.012500\n",
            "2020-12-22 09:53:52,003 epoch 46 - iter 460/469 - loss 0.19256406 - samples/sec: 273.36 - lr: 0.012500\n",
            "2020-12-22 09:53:53,128 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-22 09:53:53,130 EPOCH 46 done: loss 0.1916 - lr 0.0125000\n",
            "2020-12-22 09:53:58,364 DEV : loss 0.3948989510536194 - score 0.9556\n",
            "Epoch    46: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2020-12-22 09:53:58,383 BAD EPOCHS (no improvement): 4\n",
            "2020-12-22 09:53:58,384 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-22 09:54:03,919 epoch 47 - iter 46/469 - loss 0.17405728 - samples/sec: 266.17 - lr: 0.006250\n",
            "2020-12-22 09:54:09,396 epoch 47 - iter 92/469 - loss 0.18633544 - samples/sec: 268.97 - lr: 0.006250\n",
            "2020-12-22 09:54:15,056 epoch 47 - iter 138/469 - loss 0.18751332 - samples/sec: 260.31 - lr: 0.006250\n",
            "2020-12-22 09:54:20,701 epoch 47 - iter 184/469 - loss 0.18912295 - samples/sec: 260.98 - lr: 0.006250\n",
            "2020-12-22 09:54:26,335 epoch 47 - iter 230/469 - loss 0.18885488 - samples/sec: 261.47 - lr: 0.006250\n",
            "2020-12-22 09:54:32,029 epoch 47 - iter 276/469 - loss 0.18829600 - samples/sec: 258.69 - lr: 0.006250\n",
            "2020-12-22 09:54:37,669 epoch 47 - iter 322/469 - loss 0.18795980 - samples/sec: 261.18 - lr: 0.006250\n",
            "2020-12-22 09:54:43,199 epoch 47 - iter 368/469 - loss 0.18925873 - samples/sec: 266.35 - lr: 0.006250\n",
            "2020-12-22 09:54:48,683 epoch 47 - iter 414/469 - loss 0.18977588 - samples/sec: 268.62 - lr: 0.006250\n",
            "2020-12-22 09:54:54,279 epoch 47 - iter 460/469 - loss 0.18877105 - samples/sec: 263.27 - lr: 0.006250\n",
            "2020-12-22 09:54:55,508 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-22 09:54:55,510 EPOCH 47 done: loss 0.1889 - lr 0.0062500\n",
            "2020-12-22 09:55:00,509 DEV : loss 0.3957512080669403 - score 0.9561\n",
            "2020-12-22 09:55:00,529 BAD EPOCHS (no improvement): 1\n",
            "2020-12-22 09:55:00,531 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-22 09:55:06,115 epoch 48 - iter 46/469 - loss 0.20156209 - samples/sec: 263.85 - lr: 0.006250\n",
            "2020-12-22 09:55:11,737 epoch 48 - iter 92/469 - loss 0.17996667 - samples/sec: 262.10 - lr: 0.006250\n",
            "2020-12-22 09:55:17,206 epoch 48 - iter 138/469 - loss 0.18077758 - samples/sec: 269.40 - lr: 0.006250\n",
            "2020-12-22 09:55:23,073 epoch 48 - iter 184/469 - loss 0.18360343 - samples/sec: 251.03 - lr: 0.006250\n",
            "2020-12-22 09:55:28,546 epoch 48 - iter 230/469 - loss 0.18230290 - samples/sec: 269.15 - lr: 0.006250\n",
            "2020-12-22 09:55:34,147 epoch 48 - iter 276/469 - loss 0.18090184 - samples/sec: 263.03 - lr: 0.006250\n",
            "2020-12-22 09:55:39,908 epoch 48 - iter 322/469 - loss 0.18002505 - samples/sec: 255.76 - lr: 0.006250\n",
            "2020-12-22 09:55:45,555 epoch 48 - iter 368/469 - loss 0.17991163 - samples/sec: 260.79 - lr: 0.006250\n",
            "2020-12-22 09:55:51,127 epoch 48 - iter 414/469 - loss 0.18084309 - samples/sec: 264.40 - lr: 0.006250\n",
            "2020-12-22 09:55:56,827 epoch 48 - iter 460/469 - loss 0.18169525 - samples/sec: 258.37 - lr: 0.006250\n",
            "2020-12-22 09:55:57,883 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-22 09:55:57,886 EPOCH 48 done: loss 0.1824 - lr 0.0062500\n",
            "2020-12-22 09:56:03,005 DEV : loss 0.3927677869796753 - score 0.957\n",
            "2020-12-22 09:56:03,024 BAD EPOCHS (no improvement): 2\n",
            "2020-12-22 09:56:03,026 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-22 09:56:08,733 epoch 49 - iter 46/469 - loss 0.18125371 - samples/sec: 258.09 - lr: 0.006250\n",
            "2020-12-22 09:56:14,120 epoch 49 - iter 92/469 - loss 0.17649947 - samples/sec: 273.49 - lr: 0.006250\n",
            "2020-12-22 09:56:19,614 epoch 49 - iter 138/469 - loss 0.18228679 - samples/sec: 268.09 - lr: 0.006250\n",
            "2020-12-22 09:56:25,292 epoch 49 - iter 184/469 - loss 0.18311399 - samples/sec: 259.43 - lr: 0.006250\n",
            "2020-12-22 09:56:30,936 epoch 49 - iter 230/469 - loss 0.18255145 - samples/sec: 261.06 - lr: 0.006250\n",
            "2020-12-22 09:56:36,545 epoch 49 - iter 276/469 - loss 0.18490649 - samples/sec: 262.60 - lr: 0.006250\n",
            "2020-12-22 09:56:42,079 epoch 49 - iter 322/469 - loss 0.18898536 - samples/sec: 266.24 - lr: 0.006250\n",
            "2020-12-22 09:56:47,739 epoch 49 - iter 368/469 - loss 0.19141954 - samples/sec: 260.28 - lr: 0.006250\n",
            "2020-12-22 09:56:53,448 epoch 49 - iter 414/469 - loss 0.19109738 - samples/sec: 257.99 - lr: 0.006250\n",
            "2020-12-22 09:56:59,300 epoch 49 - iter 460/469 - loss 0.19239001 - samples/sec: 251.80 - lr: 0.006250\n",
            "2020-12-22 09:57:00,405 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-22 09:57:00,406 EPOCH 49 done: loss 0.1921 - lr 0.0062500\n",
            "2020-12-22 09:57:05,726 DEV : loss 0.39464640617370605 - score 0.957\n",
            "2020-12-22 09:57:05,742 BAD EPOCHS (no improvement): 3\n",
            "2020-12-22 09:57:05,744 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-22 09:57:11,428 epoch 50 - iter 46/469 - loss 0.20883515 - samples/sec: 259.23 - lr: 0.006250\n",
            "2020-12-22 09:57:17,039 epoch 50 - iter 92/469 - loss 0.19407630 - samples/sec: 262.54 - lr: 0.006250\n",
            "2020-12-22 09:57:22,731 epoch 50 - iter 138/469 - loss 0.19143371 - samples/sec: 258.75 - lr: 0.006250\n",
            "2020-12-22 09:57:28,263 epoch 50 - iter 184/469 - loss 0.19171488 - samples/sec: 266.32 - lr: 0.006250\n",
            "2020-12-22 09:57:33,923 epoch 50 - iter 230/469 - loss 0.18859996 - samples/sec: 260.24 - lr: 0.006250\n",
            "2020-12-22 09:57:39,676 epoch 50 - iter 276/469 - loss 0.18891826 - samples/sec: 256.02 - lr: 0.006250\n",
            "2020-12-22 09:57:45,336 epoch 50 - iter 322/469 - loss 0.18529856 - samples/sec: 260.23 - lr: 0.006250\n",
            "2020-12-22 09:57:51,380 epoch 50 - iter 368/469 - loss 0.18582119 - samples/sec: 243.68 - lr: 0.006250\n",
            "2020-12-22 09:57:57,009 epoch 50 - iter 414/469 - loss 0.18543157 - samples/sec: 261.63 - lr: 0.006250\n",
            "2020-12-22 09:58:02,600 epoch 50 - iter 460/469 - loss 0.18749920 - samples/sec: 263.43 - lr: 0.006250\n",
            "2020-12-22 09:58:03,759 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-22 09:58:03,760 EPOCH 50 done: loss 0.1873 - lr 0.0062500\n",
            "2020-12-22 09:58:08,796 DEV : loss 0.3971256911754608 - score 0.9564\n",
            "Epoch    50: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2020-12-22 09:58:08,815 BAD EPOCHS (no improvement): 4\n",
            "2020-12-22 09:58:12,459 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-22 09:58:12,460 Testing using best model ...\n",
            "2020-12-22 09:58:12,461 loading file /content/model/conllpp/best-model.pt\n",
            "2020-12-22 09:58:54,945 0.9350\t0.9358\t0.9354\n",
            "2020-12-22 09:58:54,946 \n",
            "Results:\n",
            "- F1-score (micro) 0.9354\n",
            "- F1-score (macro) 0.9231\n",
            "\n",
            "By class:\n",
            "LOC        tp: 1571 - fp: 74 - fn: 75 - precision: 0.9550 - recall: 0.9544 - f1-score: 0.9547\n",
            "MISC       tp: 613 - fp: 117 - fn: 110 - precision: 0.8397 - recall: 0.8479 - f1-score: 0.8438\n",
            "ORG        tp: 1573 - fp: 152 - fn: 142 - precision: 0.9119 - recall: 0.9172 - f1-score: 0.9145\n",
            "PER        tp: 1579 - fp: 28 - fn: 39 - precision: 0.9826 - recall: 0.9759 - f1-score: 0.9792\n",
            "2020-12-22 09:58:54,946 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [0.8842470645904541,\n",
              "  0.6657153367996216,\n",
              "  0.6118857860565186,\n",
              "  0.5008137226104736,\n",
              "  0.4860352575778961,\n",
              "  0.4302758574485779,\n",
              "  0.4089862108230591,\n",
              "  0.42747071385383606,\n",
              "  0.42218390107154846,\n",
              "  0.3961328864097595,\n",
              "  0.40525907278060913,\n",
              "  0.418643593788147,\n",
              "  0.39092108607292175,\n",
              "  0.39777839183807373,\n",
              "  0.37682512402534485,\n",
              "  0.3839797377586365,\n",
              "  0.3861132562160492,\n",
              "  0.4215836226940155,\n",
              "  0.3822997510433197,\n",
              "  0.3758755326271057,\n",
              "  0.3812239468097687,\n",
              "  0.3922078609466553,\n",
              "  0.38810276985168457,\n",
              "  0.39218172430992126,\n",
              "  0.37520965933799744,\n",
              "  0.3797110617160797,\n",
              "  0.3728858232498169,\n",
              "  0.3682883679866791,\n",
              "  0.37996965646743774,\n",
              "  0.3890150487422943,\n",
              "  0.374748557806015,\n",
              "  0.3783147931098938,\n",
              "  0.3799239993095398,\n",
              "  0.39099475741386414,\n",
              "  0.3870539367198944,\n",
              "  0.3900368809700012,\n",
              "  0.3956044018268585,\n",
              "  0.41062259674072266,\n",
              "  0.3880603313446045,\n",
              "  0.40031811594963074,\n",
              "  0.3976965546607971,\n",
              "  0.3934156596660614,\n",
              "  0.3969409465789795,\n",
              "  0.3988956809043884,\n",
              "  0.39434903860092163,\n",
              "  0.3948989510536194,\n",
              "  0.3957512080669403,\n",
              "  0.3927677869796753,\n",
              "  0.39464640617370605,\n",
              "  0.3971256911754608],\n",
              " 'dev_score_history': [0.8986991187578683,\n",
              "  0.9217171717171717,\n",
              "  0.9181680417578718,\n",
              "  0.934086311530681,\n",
              "  0.9393452330598089,\n",
              "  0.9404051441539885,\n",
              "  0.9448513934495243,\n",
              "  0.9433740008413967,\n",
              "  0.9436785474108945,\n",
              "  0.9491753618310333,\n",
              "  0.9488622050550005,\n",
              "  0.9461570768584628,\n",
              "  0.9501263689974726,\n",
              "  0.951108870967742,\n",
              "  0.9499412061145641,\n",
              "  0.9508417508417509,\n",
              "  0.9525966943535531,\n",
              "  0.9481830417227456,\n",
              "  0.952756566249895,\n",
              "  0.9546599496221663,\n",
              "  0.9543659131019413,\n",
              "  0.9546447169494373,\n",
              "  0.9544424867858042,\n",
              "  0.9541253570828432,\n",
              "  0.9554921061471281,\n",
              "  0.9557121288374434,\n",
              "  0.9550033579583612,\n",
              "  0.955878645264308,\n",
              "  0.9549428379287156,\n",
              "  0.9550033579583612,\n",
              "  0.9559811827956989,\n",
              "  0.9563902193093018,\n",
              "  0.9575075579442393,\n",
              "  0.958025520483546,\n",
              "  0.9567335965722926,\n",
              "  0.9570253483296962,\n",
              "  0.9557700377675198,\n",
              "  0.9561639234128317,\n",
              "  0.9572232960753003,\n",
              "  0.9558798859251803,\n",
              "  0.9566020313942752,\n",
              "  0.9556600604635539,\n",
              "  0.9552814833459182,\n",
              "  0.9554193602552264,\n",
              "  0.9555798135863633,\n",
              "  0.9555798135863633,\n",
              "  0.9560983799210945,\n",
              "  0.9569892473118279,\n",
              "  0.9570036949949613,\n",
              "  0.9564268323398539],\n",
              " 'test_score': 0.935401875712157,\n",
              " 'train_loss_history': [2.551533189536666,\n",
              "  1.1692549694639278,\n",
              "  0.9303556108779745,\n",
              "  0.8043785020232455,\n",
              "  0.7080886515536542,\n",
              "  0.6532514937269662,\n",
              "  0.6064197164354548,\n",
              "  0.5730806246622285,\n",
              "  0.5362393475099921,\n",
              "  0.5124937541512792,\n",
              "  0.4822604288297421,\n",
              "  0.4683046129339539,\n",
              "  0.4478592034786749,\n",
              "  0.4306833285893967,\n",
              "  0.4162981713822147,\n",
              "  0.3990356306722169,\n",
              "  0.3900270112164652,\n",
              "  0.3820033221483739,\n",
              "  0.36892495493390665,\n",
              "  0.3505000861278221,\n",
              "  0.34685158932895294,\n",
              "  0.32813445867887187,\n",
              "  0.3280206887261954,\n",
              "  0.3219557977053148,\n",
              "  0.29480191950859036,\n",
              "  0.274641029679699,\n",
              "  0.26599528565843983,\n",
              "  0.26379060805606436,\n",
              "  0.2442145360701247,\n",
              "  0.2563256544630919,\n",
              "  0.24069270221536349,\n",
              "  0.23855824314200802,\n",
              "  0.23505642177707858,\n",
              "  0.22676113313004406,\n",
              "  0.23682269352331345,\n",
              "  0.2336606545044161,\n",
              "  0.22870815450003915,\n",
              "  0.21198526387021485,\n",
              "  0.20973330883901004,\n",
              "  0.20567792924101164,\n",
              "  0.20396366235671012,\n",
              "  0.20459862035919607,\n",
              "  0.20106734411675792,\n",
              "  0.1954003737123409,\n",
              "  0.18936010788498656,\n",
              "  0.19158870274069975,\n",
              "  0.1888507132781848,\n",
              "  0.18235911162041907,\n",
              "  0.19207012796325723,\n",
              "  0.18731572712535288]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zX1abswOTdfl"
      },
      "source": [
        "We see that the output accuracy (F1-score) for our new model is **93.5%** (F1-score (micro) 0.9354)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbaB4a27Tq7P"
      },
      "source": [
        "## Using the Model (Running Inference)\r\n",
        "\r\n",
        "Running the model to do some predictions/inference is as simple as calling `tagger.predict(sentence)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOtVbbI1Jsdz",
        "outputId": "018adaba-eb2c-4aa5-9b12-bdf8ff072eff"
      },
      "source": [
        "from flair.data import Sentence\r\n",
        "from flair.models import SequenceTagger\r\n",
        "\r\n",
        "input_sentence = 'My name is Eugene, I currently live in Singapore, I work for DSO.'\r\n",
        "tagger: SequenceTagger = SequenceTagger.load(\"/content/model/conllpp/final-model.pt\")\r\n",
        "sentence: Sentence = Sentence(input_sentence)\r\n",
        "tagger.predict(sentence)\r\n",
        "print(sentence.to_tagged_string())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-22 10:02:26,649 loading file /content/model/conllpp/final-model.pt\n",
            "My name is Eugene <B-PER> , I currently live in Singapore <B-LOC> , I work for DSO <B-ORG> .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_PbWkOxUoXk"
      },
      "source": [
        "We can connect to Google Drive with the following code to save any files you want to persist. You can also click the `Files` icon on the left panel and click `Mount Drive` to mount your Google Drive.\r\n",
        "\r\n",
        "The root of your Google Drive will be mounted to `/content/drive/My Drive/`. If you have problems mounting the drive, you can check out this [tutorial](https://towardsdatascience.com/downloading-datasets-into-google-drive-via-google-colab-bcb1b30b0166)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGqgwwvkUuNv"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kh9_zd6aUqMG"
      },
      "source": [
        "You can move the model files from our local directory to your Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P7UpDkVUyQQ"
      },
      "source": [
        "import shutil\r\n",
        "shutil.move('/content/model/conllpp/', \"/content/drive/My Drive/model/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bpu244PQUyso"
      },
      "source": [
        "More Notebooks @ [eugenesiow/practical-ml](https://github.com/eugenesiow/practical-ml) and do drop us some feedback on how to improve the notebooks on the [Github repo](https://github.com/eugenesiow/practical-ml/)."
      ]
    }
  ]
}